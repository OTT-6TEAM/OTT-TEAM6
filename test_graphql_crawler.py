# ==========================================================
# IMDB GraphQL API í¬ë¡¤ëŸ¬ - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
# ì†ŒëŸ‰ì˜ ë°ì´í„°ë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸
# ==========================================================

import asyncio
import aiohttp
import json
from imdb_graphql_crawler import (
    build_graphql_url,
    fetch_graphql,
    parse_review_node,
    fetch_all_reviews_for_series,
    RateLimiter,
    rate_limiter
)

# í…ŒìŠ¤íŠ¸ìš© IMDB ID
TEST_SERIES = [
    {"imdb_id": "tt0944947", "title": "Game of Thrones"},
    {"imdb_id": "tt0903747", "title": "Breaking Bad"},
    {"imdb_id": "tt2306299", "title": "Vikings"},
]

async def test_graphql_api():
    """GraphQL API ê¸°ë³¸ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ğŸ§ª IMDB GraphQL API í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    connector = aiohttp.TCPConnector(limit=5)
    timeout = aiohttp.ClientTimeout(total=30)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        for series in TEST_SERIES:
            imdb_id = series['imdb_id']
            title = series['title']
            
            print(f"\nğŸ“¥ í…ŒìŠ¤íŠ¸ ì¤‘: {title} ({imdb_id})")
            
            # ì²« í˜ì´ì§€ë§Œ ê°€ì ¸ì˜¤ê¸°
            url = build_graphql_url(imdb_id, first=5)
            print(f"ğŸ”— URL (ì²« 5ê°œ ë¦¬ë·°): {url[:100]}...")
            
            response = await fetch_graphql(session, url)
            
            if response:
                # êµ¬ì¡° í™•ì¸
                data = response.get('data', {})
                title_data = data.get('title', {})
                reviews_data = title_data.get('reviews', {})
                
                total = reviews_data.get('total', 0)
                edges = reviews_data.get('edges', [])
                
                print(f"   âœ… ì´ ë¦¬ë·° ìˆ˜: {total:,}ê°œ")
                print(f"   âœ… ë°›ì€ ë¦¬ë·°: {len(edges)}ê°œ")
                
                # ì²« ë²ˆì§¸ ë¦¬ë·° íŒŒì‹±
                if edges:
                    first_review = parse_review_node(edges[0]['node'], imdb_id)
                    if first_review:
                        print(f"\n   ğŸ“ ì²« ë²ˆì§¸ ë¦¬ë·°:")
                        print(f"      ì‘ì„±ì: {first_review['username']}")
                        print(f"      í‰ì : {first_review['author_rating']}/10")
                        print(f"      ë‚ ì§œ: {first_review['submission_date']}")
                        print(f"      ì œëª©: {first_review['review_title']}")
                        print(f"      ë‚´ìš©: {first_review['review_text'][:100]}...")
                        print(f"      Helpful: {first_review['helpful_up_votes']}/{first_review['helpful_total']}")
            else:
                print(f"   âŒ API í˜¸ì¶œ ì‹¤íŒ¨")
            
            await asyncio.sleep(1)
    
    print("\n" + "=" * 70)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)

async def test_full_collection():
    """ì „ì²´ ë¦¬ë·° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (1ê°œ ì‹œë¦¬ì¦ˆë§Œ)"""
    print("\n" + "=" * 70)
    print("ğŸ§ª ì „ì²´ ë¦¬ë·° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (Game of Thrones)")
    print("=" * 70)
    
    connector = aiohttp.TCPConnector(limit=5)
    timeout = aiohttp.ClientTimeout(total=30)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # Game of Thrones ë¦¬ë·° 100ê°œë§Œ ìˆ˜ì§‘
        reviews = await fetch_all_reviews_for_series(
            session,
            "tt0944947",
            "Game of Thrones",
            max_reviews=100
        )
        
        print(f"\nâœ… ìˆ˜ì§‘ëœ ë¦¬ë·°: {len(reviews)}ê°œ")
        
        if reviews:
            import pandas as pd
            df = pd.DataFrame(reviews)
            
            print("\nğŸ“Š í†µê³„:")
            print(f"   í‰ê·  í‰ì : {df['author_rating'].mean():.2f}/10")
            print(f"   í‰ê·  ê¸¸ì´: {df['review_text_length'].mean():.0f}ì")
            print(f"   Spoiler: {df['is_spoiler'].sum()}ê°œ")
            
            # ìƒ˜í”Œ ì €ì¥
            df.to_csv('test_reviews_sample.csv', index=False, encoding='utf-8-sig')
            print(f"\nâœ… ìƒ˜í”Œ ì €ì¥: test_reviews_sample.csv")

async def test_url_generation():
    """URL ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ğŸ§ª URL ìƒì„± í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # ì²« í˜ì´ì§€
    url1 = build_graphql_url("tt0944947", first=25)
    print(f"\n1ï¸âƒ£ ì²« í˜ì´ì§€ URL:")
    print(f"   {url1[:150]}...")
    
    # ë‘ ë²ˆì§¸ í˜ì´ì§€ (ì»¤ì„œ ìˆìŒ)
    url2 = build_graphql_url(
        "tt0944947",
        after_cursor="g4xopermtizcsyya76whvnburdr4yazs3modv7pjdpj3qflanarkwdc6oi2u7w5il4pln667fmielj3jr4cuobss",
        first=25
    )
    print(f"\n2ï¸âƒ£ ë‘ ë²ˆì§¸ í˜ì´ì§€ URL (ì»¤ì„œ í¬í•¨):")
    print(f"   {url2[:150]}...")
    
    # ì •ë ¬ ê¸°ì¤€ ë³€ê²½
    url3 = build_graphql_url("tt0944947", first=25, sort_by="SUBMISSION_DATE")
    print(f"\n3ï¸âƒ£ ë‚ ì§œ ì •ë ¬ URL:")
    print(f"   {url3[:150]}...")

if __name__ == "__main__":
    import sys
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     IMDB GraphQL API í¬ë¡¤ëŸ¬ - í…ŒìŠ¤íŠ¸ ë©”ë‰´            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. URL ìƒì„± í…ŒìŠ¤íŠ¸ (ë¹ ë¦„)
2. API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (3ê°œ ì‹œë¦¬ì¦ˆ)
3. ì „ì²´ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (1ê°œ ì‹œë¦¬ì¦ˆ, 100ê°œ ë¦¬ë·°)
4. ëª¨ë‘ ì‹¤í–‰

ì„ íƒ: """, end='')
    
    try:
        choice = input().strip()
    except:
        choice = "4"
    
    if choice == "1":
        asyncio.run(test_url_generation())
    elif choice == "2":
        asyncio.run(test_graphql_api())
    elif choice == "3":
        asyncio.run(test_full_collection())
    else:
        asyncio.run(test_url_generation())
        asyncio.run(test_graphql_api())
        asyncio.run(test_full_collection())
    
    print("\nâœ¨ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆë‹¤ë©´ ë³¸ê²©ì ì¸ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”:")
    print("   python imdb_graphql_crawler.py --vote 30")

# ë“œë¼ë§ˆ Overview í…ìŠ¤íŠ¸ ì„ë² ë”© ê°€ì´ë“œ

## ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install sentence-transformers pandas pyarrow tqdm numpy

# ë˜ëŠ” requirements.txtë¡œ ì„¤ì¹˜
pip install -r requirements.txt
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ì¶”ì²œ)

```bash
python drama_embedding_simple.py
```

ì´ ë°©ë²•ì´ ê°€ì¥ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì…ë‹ˆë‹¤!

### ë°©ë²• 2: ê³ ê¸‰ ê¸°ëŠ¥ í¬í•¨ ìŠ¤í¬ë¦½íŠ¸

```bash
python drama_embedding.py
```

ì´ ë°©ë²•ì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤:
- ì¤‘ê°„ ì €ì¥ ì²´í¬í¬ì¸íŠ¸ (ë§¤ 100 ë°°ì¹˜ë§ˆë‹¤)
- ë” ìì„¸í•œ ë¡œê¹…
- ê²€ì¦ ê¸°ëŠ¥

### ë°©ë²• 3: Jupyter Notebookì—ì„œ ì§ì ‘ ì‹¤í–‰

```python
import pandas as pd
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# 1. ë°ì´í„° ë¡œë“œ
drama_final = pd.read_parquet("ìµœì¢…ë°ì´í„°ì…‹_ë“œë¼ë§ˆ/drama_final.parquet")

# 2. ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')

# 3. ì„ë² ë”© ìƒì„±
texts = drama_final['overview'].fillna("").tolist()
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)

# 4. ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
drama_final['embedding'] = list(embeddings)

# 5. ì €ì¥
drama_final.to_csv("drama_embeddings_progress.csv", index=False)
drama_final.to_parquet("drama_with_embeddings.parquet", index=False)

print("ì™„ë£Œ!")
```

## ğŸ“Š ì¶œë ¥ íŒŒì¼

1. **drama_embeddings_progress.csv** - ì¤‘ê°„ ê²°ê³¼ (CSV í˜•ì‹)
2. **drama_with_embeddings.parquet** - ìµœì¢… ê²°ê³¼ (Parquet í˜•ì‹, ì••ì¶•ë¨)

## âš™ï¸ ì„¤ì • ì˜µì…˜

### batch_size ì¡°ì •
- **GPUê°€ ìˆëŠ” ê²½ìš°**: 64 ë˜ëŠ” 128ë¡œ ì¦ê°€ â†’ ë” ë¹ ë¦„
- **ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°**: 16 ë˜ëŠ” 8ë¡œ ê°ì†Œ â†’ ëŠë¦¬ì§€ë§Œ ì•ˆì •ì 

```python
# drama_embedding_simple.pyì—ì„œ ì´ ì¤„ì„ ìˆ˜ì •:
batch_size = 32  # ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ë³€ê²½
```

## ğŸ” ê²°ê³¼ í™•ì¸

```python
import pandas as pd

# Parquet íŒŒì¼ ì½ê¸°
df = pd.read_parquet("drama_with_embeddings.parquet")

# ê¸°ë³¸ ì •ë³´
print(f"ë°ì´í„° shape: {df.shape}")
print(f"ì»¬ëŸ¼: {df.columns.tolist()}")

# ì„ë² ë”© í™•ì¸
print(f"ì„ë² ë”© ì°¨ì›: {len(df.iloc[0]['embedding'])}")
print(f"ì²« ë²ˆì§¸ ì„ë² ë”© ìƒ˜í”Œ: {df.iloc[0]['embedding'][:5]}")
```

## ğŸ“ˆ ì„±ëŠ¥ íŒ

1. **GPU ì‚¬ìš©** (ê°€ëŠ¥í•œ ê²½ìš°)
   - CUDAê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ GPU ì‚¬ìš©
   - CPUë³´ë‹¤ 10-50ë°° ë¹ ë¦„

2. **ë°°ì¹˜ í¬ê¸° ìµœì í™”**
   - GPU ë©”ëª¨ë¦¬: 8GB â†’ batch_size=64
   - GPU ë©”ëª¨ë¦¬: 4GB â†’ batch_size=32
   - CPUë§Œ ì‚¬ìš© â†’ batch_size=16

3. **ì˜ˆìƒ ì†Œìš” ì‹œê°„**
   - 1,000ê°œ ë“œë¼ë§ˆ: ì•½ 1-2ë¶„ (GPU) / 5-10ë¶„ (CPU)
   - 10,000ê°œ ë“œë¼ë§ˆ: ì•½ 10-20ë¶„ (GPU) / 50-100ë¶„ (CPU)

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬
```python
# batch_sizeë¥¼ ì¤„ì´ì„¸ìš”
batch_size = 16  # ë˜ëŠ” 8
```

### CUDA ì—ëŸ¬
```python
# CPU ê°•ì œ ì‚¬ìš©
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼
- ì²« ì‹¤í–‰ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 400MB)
- ì´í›„ì—ëŠ” ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ ë¹ ë¦„

## ğŸ“Œ ëª¨ë¸ ì •ë³´

**sentence-transformers/all-mpnet-base-v2**
- ì„ë² ë”© ì°¨ì›: 768
- ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 384 í† í°
- ì–¸ì–´: ì˜ì–´
- ìš©ë„: ë¬¸ì¥/í…ìŠ¤íŠ¸ ìœ ì‚¬ë„, ê²€ìƒ‰, í´ëŸ¬ìŠ¤í„°ë§

## ğŸ’¡ í™œìš© ì˜ˆì œ

### 1. ìœ ì‚¬ ë“œë¼ë§ˆ ì°¾ê¸°
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# ì„ë² ë”© ë°°ì—´ë¡œ ë³€í™˜
embedding_matrix = np.vstack(df['embedding'].values)

# ì²« ë²ˆì§¸ ë“œë¼ë§ˆì™€ ìœ ì‚¬í•œ ë“œë¼ë§ˆ ì°¾ê¸°
similarities = cosine_similarity([embedding_matrix[0]], embedding_matrix)[0]
top_5_idx = np.argsort(similarities)[-6:-1][::-1]  # ìê¸° ìì‹  ì œì™¸

print("ìœ ì‚¬í•œ ë“œë¼ë§ˆ:")
for idx in top_5_idx:
    print(f"- {df.iloc[idx]['overview'][:100]}...")
    print(f"  ìœ ì‚¬ë„: {similarities[idx]:.3f}\n")
```

### 2. ë“œë¼ë§ˆ í´ëŸ¬ìŠ¤í„°ë§
```python
from sklearn.cluster import KMeans

# K-Means í´ëŸ¬ìŠ¤í„°ë§
kmeans = KMeans(n_clusters=10, random_state=42)
df['cluster'] = kmeans.fit_predict(embedding_matrix)

# í´ëŸ¬ìŠ¤í„°ë³„ ë“œë¼ë§ˆ ìˆ˜
print(df['cluster'].value_counts())
```

### 3. í‚¤ì›Œë“œë¡œ ë“œë¼ë§ˆ ê²€ìƒ‰
```python
# ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”©
query = "crime investigation detective"
query_embedding = model.encode([query])[0]

# ìœ ì‚¬ë„ ê³„ì‚°
similarities = cosine_similarity([query_embedding], embedding_matrix)[0]
top_10_idx = np.argsort(similarities)[-10:][::-1]

print(f"'{query}' ê²€ìƒ‰ ê²°ê³¼:")
for idx in top_10_idx:
    print(f"- {df.iloc[idx]['overview'][:100]}...")
    print(f"  ìœ ì‚¬ë„: {similarities[idx]:.3f}\n")
```
